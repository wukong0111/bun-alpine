import { gzipSync } from "node:zlib";
import { db } from "../database/database";

export interface BackupMetadata {
	timestamp: string;
	version: string;
	nodeEnv: string;
	databaseSize: number;
	tableCount: number;
	recordCount: {
		users: number;
		languages: number;
		votes: number;
		user_monthly_votes: number;
	};
	postgresVersion?: string;
	databaseName: string;
}

export async function createDatabaseBackup(): Promise<{
	data: Buffer;
	metadata: BackupMetadata;
	filename: string;
}> {
	try {
		// Crear dump SQL completo de PostgreSQL
		const sqlDump = await generatePostgreSQLDump();

		// Obtener metadata
		const metadata = await getBackupMetadata();

		// Crear contenido del backup
		const backupContent = {
			metadata,
			sqlDump,
			createdAt: new Date().toISOString(),
			type: "postgresql",
		};

		// Comprimir el backup
		const jsonContent = JSON.stringify(backupContent, null, 2);
		const compressedData = gzipSync(Buffer.from(jsonContent, "utf-8"));

		// Nombre del archivo
		const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
		const filename = `backup-postgresql-${timestamp}.sql.gz`;

		return {
			data: compressedData,
			metadata,
			filename,
		};
	} catch (error) {
		console.error("Error creating PostgreSQL database backup:", error);
		throw new Error("Failed to create PostgreSQL database backup");
	}
}

async function generatePostgreSQLDump(): Promise<string> {
	let sqlDump = "";

	// Agregar header
	sqlDump += `-- PostgreSQL database backup created on ${new Date().toISOString()}\n`;
	sqlDump += `-- Generated by Bun Alpine Ranking System\n`;
	sqlDump += `-- PostgreSQL version: ${await getPostgreSQLVersion()}\n\n`;

	// Configuraciones iniciales
	sqlDump += `SET statement_timeout = 0;\n`;
	sqlDump += `SET lock_timeout = 0;\n`;
	sqlDump += `SET client_encoding = 'UTF8';\n`;
	sqlDump += `SET standard_conforming_strings = on;\n`;
	sqlDump += `SET check_function_bodies = false;\n`;
	sqlDump += `SET xmloption = content;\n`;
	sqlDump += `SET client_min_messages = warning;\n\n`;

	// Obtener lista de tablas en orden correcto (respetando dependencias)
	const tableOrder = ["languages", "users", "user_monthly_votes", "votes"];

	// Generar esquema y datos para cada tabla
	for (const tableName of tableOrder) {
		try {
			// Obtener esquema de la tabla
			const schemaResult = await db`
        SELECT 
          'CREATE TABLE ' || schemaname||'.'||tablename || ' (' || string_agg(column_definition, ', ') || ');' as create_statement
        FROM (
          SELECT 
            schemaname,
            tablename,
            column_name || ' ' || data_type || 
            CASE 
              WHEN character_maximum_length IS NOT NULL THEN '(' || character_maximum_length || ')'
              WHEN numeric_precision IS NOT NULL AND numeric_scale IS NOT NULL THEN '(' || numeric_precision || ',' || numeric_scale || ')'
              ELSE ''
            END ||
            CASE 
              WHEN is_nullable = 'NO' THEN ' NOT NULL'
              ELSE ''
            END ||
            CASE 
              WHEN column_default IS NOT NULL THEN ' DEFAULT ' || column_default
              ELSE ''
            END as column_definition
          FROM information_schema.columns
          WHERE table_schema = 'public' AND table_name = ${tableName}
          ORDER BY ordinal_position
        ) cols
        GROUP BY schemaname, tablename
      `;

			if (schemaResult.length > 0) {
				sqlDump += `-- Table: ${tableName}\n`;
				sqlDump += `DROP TABLE IF EXISTS ${tableName} CASCADE;\n`;
				sqlDump += `${schemaResult[0]?.create_statement || ""}\n\n`;

				// Obtener datos de la tabla
				const rows = await db`SELECT * FROM ${db(tableName)}`;

				if (rows.length > 0) {
					// Obtener nombres de columnas
					const columns = Object.keys(rows[0] as Record<string, unknown>);
					const columnNames = columns.join(", ");

					sqlDump += `-- Data for table: ${tableName}\n`;

					for (const row of rows) {
						const values = columns.map((col) => {
							const value = (row as Record<string, unknown>)[col];
							if (value === null) return "NULL";
							if (typeof value === "string")
								return `'${value.replace(/'/g, "''")}'`;
							if (typeof value === "boolean") return value ? "true" : "false";
							if (value instanceof Date) return `'${value.toISOString()}'`;
							return value;
						});

						sqlDump += `INSERT INTO ${tableName} (${columnNames}) VALUES (${values.join(", ")});\n`;
					}

					sqlDump += "\n";
				}
			}
		} catch (error) {
			console.warn(`Warning: Could not backup table ${tableName}:`, error);
		}
	}

	// Agregar índices
	try {
		const indexes = await db`
      SELECT 
        schemaname,
        indexname,
        indexdef
      FROM pg_indexes 
      WHERE schemaname = 'public'
      AND indexname NOT LIKE '%_pkey'
      ORDER BY indexname
    `;

		if (indexes.length > 0) {
			sqlDump += `-- Indexes\n`;
			for (const index of indexes) {
				sqlDump += `${index.indexdef};\n`;
			}
			sqlDump += "\n";
		}
	} catch (error) {
		console.warn("Warning: Could not backup indexes:", error);
	}

	// Agregar funciones
	try {
		const functions = await db`
      SELECT 
        proname,
        pg_get_functiondef(oid) as definition
      FROM pg_proc 
      WHERE pronamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public')
      AND prokind = 'f'
    `;

		if (functions.length > 0) {
			sqlDump += `-- Functions\n`;
			for (const func of functions) {
				sqlDump += `${func.definition};\n\n`;
			}
		}
	} catch (error) {
		console.warn("Warning: Could not backup functions:", error);
	}

	// Agregar triggers
	try {
		const triggers = await db`
      SELECT 
        trigger_name,
        event_manipulation,
        event_object_table,
        action_statement,
        action_timing
      FROM information_schema.triggers
      WHERE trigger_schema = 'public'
    `;

		if (triggers.length > 0) {
			sqlDump += `-- Triggers\n`;
			for (const trigger of triggers) {
				sqlDump += `CREATE TRIGGER ${trigger.trigger_name}\n`;
				sqlDump += `  ${trigger.action_timing} ${trigger.event_manipulation}\n`;
				sqlDump += `  ON ${trigger.event_object_table}\n`;
				sqlDump += `  FOR EACH ROW\n`;
				sqlDump += `  ${trigger.action_statement};\n\n`;
			}
		}
	} catch (error) {
		console.warn("Warning: Could not backup triggers:", error);
	}

	// Resetear secuencias
	for (const tableName of tableOrder) {
		sqlDump += `SELECT setval(pg_get_serial_sequence('${tableName}', 'id'), COALESCE(max(id), 1), max(id) IS NOT null) FROM ${tableName};\n`;
	}

	return sqlDump;
}

async function getBackupMetadata(): Promise<BackupMetadata> {
	// Obtener estadísticas de la base de datos
	const stats = {
		users: await db`SELECT COUNT(*) as count FROM users`,
		languages: await db`SELECT COUNT(*) as count FROM languages`,
		votes: await db`SELECT COUNT(*) as count FROM votes`,
		user_monthly_votes:
			await db`SELECT COUNT(*) as count FROM user_monthly_votes`,
	};

	// Obtener tamaño de la base de datos
	const dbSizeResult = await db`
    SELECT pg_database_size(current_database()) as size
  `;
	const dbSize = parseInt(dbSizeResult[0]?.size as string || "0");

	// Contar tablas
	const tableCountResult = await db`
    SELECT COUNT(*) as count 
    FROM information_schema.tables 
    WHERE table_schema = 'public'
  `;

	// Obtener versión de PostgreSQL
	const postgresVersion = await getPostgreSQLVersion();

	// Obtener nombre de la base de datos
	const dbNameResult = await db`SELECT current_database() as name`;
	const databaseName = dbNameResult[0]?.name as string || "unknown";

	return {
		timestamp: new Date().toISOString(),
		version: "2.0.0",
		nodeEnv: process.env.NODE_ENV || "development",
		databaseSize: dbSize,
		tableCount: parseInt(tableCountResult[0]?.count as string || "0"),
		recordCount: {
			users: parseInt(stats.users[0]?.count as string || "0"),
			languages: parseInt(stats.languages[0]?.count as string || "0"),
			votes: parseInt(stats.votes[0]?.count as string || "0"),
			user_monthly_votes: parseInt(stats.user_monthly_votes[0]?.count as string || "0"),
		},
		postgresVersion,
		databaseName,
	};
}

async function getPostgreSQLVersion(): Promise<string> {
	try {
		const result = await db`SELECT version() as version`;
		return result[0]?.version as string;
	} catch (_error) {
		return "Unknown";
	}
}

// Función para generar backup usando pg_dump (requiere pg_dump instalado)
export async function createPgDumpBackup(): Promise<{
	data: Buffer;
	filename: string;
}> {
	try {
		const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
		const filename = `pgdump-${timestamp}.sql.gz`;

		// Construir comando pg_dump
		const pgDumpCommand = [
			"pg_dump",
			"--host",
			process.env.DATABASE_HOST || "localhost",
			"--port",
			process.env.DATABASE_PORT || "5432",
			"--username",
			process.env.DATABASE_USER || "postgres",
			"--dbname",
			process.env.DATABASE_NAME || "ranking_dev",
			"--no-password",
			"--verbose",
			"--clean",
			"--no-acl",
			"--no-owner",
			"--format=plain",
		].join(" ");

		// Ejecutar pg_dump
		const proc = Bun.spawn({
			cmd: pgDumpCommand.split(" "),
			env: {
				...process.env,
				PGPASSWORD: process.env.DATABASE_PASSWORD || "postgres",
			},
			stdout: "pipe",
			stderr: "pipe",
		});

		const output = await new Response(proc.stdout).text();
		const compressedData = gzipSync(Buffer.from(output, "utf-8"));

		return {
			data: compressedData,
			filename,
		};
	} catch (error) {
		console.error("Error creating pg_dump backup:", error);
		throw new Error(
			"Failed to create pg_dump backup. Make sure pg_dump is installed.",
		);
	}
}
